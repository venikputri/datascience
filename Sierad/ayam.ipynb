{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "import subprocess\n",
    "\n",
    "\n",
    "# Create a local StreamingContext with two working thread and batch interval of 1 second\n",
    "sc = SparkContext(\"local[2]\", \"Ayam\")\n",
    "\n",
    "ssc = StreamingContext(sc, 30)\n",
    "\n",
    "import random\n",
    "def ayam(lines):\n",
    "    for i in range(1,20):\n",
    "        temp = random.randint(15,40)\n",
    "        hum= random.randint(1,100)\n",
    "        amo = random.randint(1,50)\n",
    "        get_value = str(temp)+';'+str(hum)+';'+str(amo)\n",
    "        get_value2 = str(temp)+' '+str(hum)+' '+str(amo)\n",
    "        subprocess.check_output('spark-submit fuzzy_logic.py '+ get_value2,shell=True)\n",
    "        with open('hasil_ayam.txt', 'w') as f:\n",
    "                f.write(get_value)\n",
    "    return get_value\n",
    "\n",
    "# Create a DStream that will connect to hostname:port, like localhost:9999\n",
    "lines = ssc.socketTextStream(\"localhost\", 9999)\n",
    "\n",
    "running_counts = lines.map(ayam)\n",
    "\n",
    "running_counts.pprint()\n",
    "\n",
    "ssc.start()             # Start the computation\n",
    "ssc.awaitTermination()  # Wait for the computation to terminate\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
