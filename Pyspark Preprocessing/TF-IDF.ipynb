{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|               items|               words|\n",
      "+---+--------------------+--------------------+\n",
      "|  0|Raw Shrimp, Seedl...|[raw, shrimp,, se...|\n",
      "|  1|Cracked Wheat, St...|[cracked, wheat,,...|\n",
      "|  2|Beet Apple Carrot...|[beet, apple, car...|\n",
      "|  3|               Vodka|             [vodka]|\n",
      "|  4|Globe Eggplant, P...|[globe, eggplant,...|\n",
      "|  5|Organic Baby Spin...|[organic, baby, s...|\n",
      "|  6|Reduced Fat Crack...|[reduced, fat, cr...|\n",
      "|  7|Organic Red Onion...|[organic, red, on...|\n",
      "|  8|Organic Cripps Pi...|[organic, cripps,...|\n",
      "|  9|Organic Baby Spin...|[organic, baby, s...|\n",
      "| 10|Uncured Beef Hot ...|[uncured, beef, h...|\n",
      "| 11|Donut House Choco...|[donut, house, ch...|\n",
      "| 12|[Concentrated But...|[[concentrated, b...|\n",
      "| 13|Raspberries, Gree...|[raspberries,, gr...|\n",
      "| 14|Original Tofurky ...|[original, tofurk...|\n",
      "| 15|Extra Hold Non-Ae...|[extra, hold, non...|\n",
      "| 16|Organic Coconut M...|[organic, coconut...|\n",
      "| 17|No. 485 Gin, Mont...|[no., 485, gin,, ...|\n",
      "| 18|Red Vine Tomato, ...|[red, vine, tomat...|\n",
      "| 19|Organic Baby Arug...|[organic, baby, a...|\n",
      "+---+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.ml.feature import Tokenizer \n",
    "df = pd.read_csv(\"/home/pygmy/Projects/Moti/public.items.csv\", sep=\"|\")\n",
    "df = spark.createDataFrame(df)\n",
    "tokenizer = Tokenizer(inputCol=\"items\", outputCol=\"words\")\n",
    "tokenizer = tokenizer.transform(df)\n",
    "tokenizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF\n",
    "hashingTF = HashingTF(numFeatures=10, inputCol=\"words\", outputCol=\"features_hashtf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashdf= hashingTF.transform(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+\n",
      "| id|               items|               words|     features_hashtf|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "|  0|Raw Shrimp, Seedl...|[raw, shrimp,, se...|(10,[1,2,3,4,5,6,...|\n",
      "|  1|Cracked Wheat, St...|[cracked, wheat,,...|(10,[0,1,2,3,4,5,...|\n",
      "|  2|Beet Apple Carrot...|[beet, apple, car...|(10,[0,1,4,5,6,7,...|\n",
      "|  3|               Vodka|             [vodka]|      (10,[4],[1.0])|\n",
      "|  4|Globe Eggplant, P...|[globe, eggplant,...|(10,[0,1,2,3,4,5,...|\n",
      "|  5|Organic Baby Spin...|[organic, baby, s...|(10,[0,1,2,3,4,5,...|\n",
      "|  6|Reduced Fat Crack...|[reduced, fat, cr...|(10,[0,1,2,3,4,5,...|\n",
      "|  7|Organic Red Onion...|[organic, red, on...|(10,[0,1,2,3,4,5,...|\n",
      "|  8|Organic Cripps Pi...|[organic, cripps,...|(10,[3,5,6,8,9],[...|\n",
      "|  9|Organic Baby Spin...|[organic, baby, s...|(10,[0,1,2,3,4,5,...|\n",
      "| 10|Uncured Beef Hot ...|[uncured, beef, h...|(10,[0,1,2,3,4,5,...|\n",
      "| 11|Donut House Choco...|[donut, house, ch...|(10,[0,1,2,3,4,5,...|\n",
      "| 12|[Concentrated But...|[[concentrated, b...|(10,[0,1,2,3,4,5,...|\n",
      "| 13|Raspberries, Gree...|[raspberries,, gr...|(10,[0,2,4,5,7,8,...|\n",
      "| 14|Original Tofurky ...|[original, tofurk...|(10,[0,1,2,3,4,5,...|\n",
      "| 15|Extra Hold Non-Ae...|[extra, hold, non...|(10,[0,1,2,3,4,5,...|\n",
      "| 16|Organic Coconut M...|[organic, coconut...|(10,[0,3,4,5,6,8,...|\n",
      "| 17|No. 485 Gin, Mont...|[no., 485, gin,, ...|(10,[0,1,2,3,4,5,...|\n",
      "| 18|Red Vine Tomato, ...|[red, vine, tomat...|(10,[0,1,2,3,4,5,...|\n",
      "| 19|Organic Baby Arug...|[organic, baby, a...|(10,[0,3,4,5,6,8,...|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, items: string, words: array<string>, features_hashtf: vector]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IDF\n",
    "idf = IDF(minDocFreq=3, inputCol=\"features_hashtf\", outputCol=\"idf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = idf.fit(hashdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel = model.transform(hashdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "| id|               items|               words|     features_hashtf|                 idf|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "|  0|Raw Shrimp, Seedl...|[raw, shrimp,, se...|(10,[1,2,3,4,5,6,...|(10,[1,2,3,4,5,6,...|\n",
      "|  1|Cracked Wheat, St...|[cracked, wheat,,...|(10,[0,1,2,3,4,5,...|(10,[0,1,2,3,4,5,...|\n",
      "|  2|Beet Apple Carrot...|[beet, apple, car...|(10,[0,1,4,5,6,7,...|(10,[0,1,4,5,6,7,...|\n",
      "|  3|               Vodka|             [vodka]|      (10,[4],[1.0])|(10,[4],[0.160373...|\n",
      "|  4|Globe Eggplant, P...|[globe, eggplant,...|(10,[0,1,2,3,4,5,...|(10,[0,1,2,3,4,5,...|\n",
      "|  5|Organic Baby Spin...|[organic, baby, s...|(10,[0,1,2,3,4,5,...|(10,[0,1,2,3,4,5,...|\n",
      "|  6|Reduced Fat Crack...|[reduced, fat, cr...|(10,[0,1,2,3,4,5,...|(10,[0,1,2,3,4,5,...|\n",
      "|  7|Organic Red Onion...|[organic, red, on...|(10,[0,1,2,3,4,5,...|(10,[0,1,2,3,4,5,...|\n",
      "|  8|Organic Cripps Pi...|[organic, cripps,...|(10,[3,5,6,8,9],[...|(10,[3,5,6,8,9],[...|\n",
      "|  9|Organic Baby Spin...|[organic, baby, s...|(10,[0,1,2,3,4,5,...|(10,[0,1,2,3,4,5,...|\n",
      "| 10|Uncured Beef Hot ...|[uncured, beef, h...|(10,[0,1,2,3,4,5,...|(10,[0,1,2,3,4,5,...|\n",
      "| 11|Donut House Choco...|[donut, house, ch...|(10,[0,1,2,3,4,5,...|(10,[0,1,2,3,4,5,...|\n",
      "| 12|[Concentrated But...|[[concentrated, b...|(10,[0,1,2,3,4,5,...|(10,[0,1,2,3,4,5,...|\n",
      "| 13|Raspberries, Gree...|[raspberries,, gr...|(10,[0,2,4,5,7,8,...|(10,[0,2,4,5,7,8,...|\n",
      "| 14|Original Tofurky ...|[original, tofurk...|(10,[0,1,2,3,4,5,...|(10,[0,1,2,3,4,5,...|\n",
      "| 15|Extra Hold Non-Ae...|[extra, hold, non...|(10,[0,1,2,3,4,5,...|(10,[0,1,2,3,4,5,...|\n",
      "| 16|Organic Coconut M...|[organic, coconut...|(10,[0,3,4,5,6,8,...|(10,[0,3,4,5,6,8,...|\n",
      "| 17|No. 485 Gin, Mont...|[no., 485, gin,, ...|(10,[0,1,2,3,4,5,...|(10,[0,1,2,3,4,5,...|\n",
      "| 18|Red Vine Tomato, ...|[red, vine, tomat...|(10,[0,1,2,3,4,5,...|(10,[0,1,2,3,4,5,...|\n",
      "| 19|Organic Baby Arug...|[organic, baby, a...|(10,[0,3,4,5,6,8,...|(10,[0,3,4,5,6,8,...|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newmodel.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dief = spark.createDataFrame([([\"a\", \"b\", \"c\"],)], [\"words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha = HashingTF(numFeatures=10, inputCol=\"words\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha = ha.transform(dief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|    words|            features|\n",
      "+---------+--------------------+\n",
      "|[a, b, c]|(10,[0,1,2],[1.0,...|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ha.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[words: array<string>, features: vector]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "aidief = IDF(minDocFreq=3, inputCol=\"features\", outputCol=\"idf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aidief = aidief.fit(ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "aidief = aidief.transform(ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+\n",
      "|    words|            features|                 idf|\n",
      "+---------+--------------------+--------------------+\n",
      "|[a, b, c]|(10,[0,1,2],[1.0,...|(10,[0,1,2],[0.0,...|\n",
      "+---------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aidief.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
